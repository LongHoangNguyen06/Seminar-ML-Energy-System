{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from pipeline import data\n",
    "from pipeline.config import CONF\n",
    "from pipeline.data import plots\n",
    "from pipeline.data import io\n",
    "from pipeline.data import inspection\n",
    "from pipeline.data import preprocess\n",
    "\n",
    "# To suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# black is a code formatter (see https://github.com/psf/black).\n",
    "# It will automatically format the code you write in the cells imposing consistent Python style.\n",
    "%load_ext jupyter_black\n",
    "# matplotlib style file\n",
    "# Template for style file: https://matplotlib.org/stable/tutorials/introductory/customizing.html#customizing-with-style-sheets\n",
    "plt.style.use(\"../matplotlib_style.txt\")\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.expand_frame_repr\", False)  # Prevent wrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data\n",
    "\n",
    "This takes about 1 minute for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data and not CONF.data.loaded_raw_data:\n",
    "    # Load raw data\n",
    "    (\n",
    "        Installed_Capacity_Germany_Raw,\n",
    "        Prices_Europe_Raw,\n",
    "        Realised_Supply_Germany_Raw,\n",
    "        Realised_Demand_Germany_Raw,\n",
    "        Weather_Data_Germany_Raw,\n",
    "        Weather_Data_Germany_2022_Raw,\n",
    "    ) = data.load_data(CONF=CONF)\n",
    "    CONF.data.loaded_raw_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data:\n",
    "    Installed_Capacity_Germany = Installed_Capacity_Germany_Raw.copy()\n",
    "    Prices_Europe = Prices_Europe_Raw.copy()\n",
    "    Realised_Supply_Germany = Realised_Supply_Germany_Raw.copy()\n",
    "    Realised_Demand_Germany = Realised_Demand_Germany_Raw.copy()\n",
    "    Weather_Data_Germany = Weather_Data_Germany_Raw.copy()\n",
    "    Weather_Data_Germany_2022 = Weather_Data_Germany_2022_Raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data:\n",
    "    # Generate profile reports\n",
    "    if CONF.data.inspect:\n",
    "        data.save_data_inspection(\n",
    "            Installed_Capacity_Germany=Installed_Capacity_Germany,\n",
    "            Prices_Europe=Prices_Europe,\n",
    "            Realised_Supply_Germany=Realised_Supply_Germany,\n",
    "            Realised_Demand_Germany=Realised_Demand_Germany,\n",
    "            Weather_Data_Germany=Weather_Data_Germany,\n",
    "            Weather_Data_Germany_2022=Weather_Data_Germany_2022,\n",
    "            CONF=CONF,\n",
    "            data_type=\"raw\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data:\n",
    "    inspection.date_range_and_resolution_dfs(\n",
    "        Installed_Capacity_Germany=Installed_Capacity_Germany,\n",
    "        Prices_Europe=Prices_Europe,\n",
    "        Realised_Supply_Germany=Realised_Supply_Germany,\n",
    "        Realised_Demand_Germany=Realised_Demand_Germany,\n",
    "        Weather_Data_Germany=Weather_Data_Germany,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.plot:\n",
    "    plots.plot_df(\n",
    "        Installed_Capacity_Germany,\n",
    "        \"Installed_Capacity_Germany\",\n",
    "        CONF,\n",
    "        processed_data=False,\n",
    "    )\n",
    "    plots.plot_df(Prices_Europe, \"Prices_Europe\", CONF, processed_data=False)\n",
    "    plots.plot_df(\n",
    "        Realised_Supply_Germany, \"Realised_Supply_Germany\", CONF, processed_data=False\n",
    "    )\n",
    "    plots.plot_df(\n",
    "        Realised_Demand_Germany, \"Realised_Demand_Germany\", CONF, processed_data=False\n",
    "    )\n",
    "    plots.plot_df(\n",
    "        Weather_Data_Germany,\n",
    "        \"Weather_Data_Germany\",\n",
    "        CONF,\n",
    "        date_col=io.DATE_COLUMNS_WEATHER[-1],\n",
    "        drop_date_cols=io.DATE_COLUMNS_WEATHER,\n",
    "        processed_data=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merging weather data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data:\n",
    "    # Remove the data for 2022 from the original dataframe\n",
    "    Weather_Data_Germany = Weather_Data_Germany[\n",
    "        Weather_Data_Germany[\"time\"].dt.year != 2022\n",
    "    ]\n",
    "\n",
    "    # Concatenate the filtered original dataframe with the 2022 data\n",
    "    Weather_Data_Germany = pd.concat(\n",
    "        [Weather_Data_Germany, Weather_Data_Germany_2022], ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data:\n",
    "    Processed_Installed_Capacity_Germany = data.process_na_values(\n",
    "        Installed_Capacity_Germany, CONF\n",
    "    )\n",
    "    Processed_Prices_Europe = data.process_na_values(Prices_Europe, CONF)\n",
    "    Processed_Realised_Supply_Germany = data.process_na_values(\n",
    "        Realised_Supply_Germany, CONF\n",
    "    )\n",
    "    Processed_Realised_Demand_Germany = data.process_na_values(\n",
    "        Realised_Demand_Germany, CONF\n",
    "    )\n",
    "    Processed_Weather_Data_Germany = data.process_na_values(Weather_Data_Germany, CONF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data:\n",
    "    Processed_Weather_Data_Germany = preprocess.aggregate_weather_data(\n",
    "        Processed_Weather_Data_Germany, [\"forecast_origin\", \"time\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decrease demand and supply's time resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data:\n",
    "    Processed_Realised_Demand_Germany = Processed_Realised_Demand_Germany[\n",
    "        Processed_Realised_Demand_Germany[\"Date to\"].dt.minute == 0\n",
    "    ]\n",
    "    Processed_Realised_Demand_Germany[\"Date from\"] = Processed_Realised_Demand_Germany[\n",
    "        \"Date to\"\n",
    "    ] - pd.Timedelta(hours=1)\n",
    "    Processed_Realised_Supply_Germany = Processed_Realised_Supply_Germany[\n",
    "        Processed_Realised_Supply_Germany[\"Date to\"].dt.minute == 0\n",
    "    ]\n",
    "    Processed_Realised_Supply_Germany[\"Date from\"] = Processed_Realised_Supply_Germany[\n",
    "        \"Date to\"\n",
    "    ] - pd.Timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increase time resolution of capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {\n",
    "    \"Date from\": pd.Timestamp(\"2022-12-31 23:00:00\"),\n",
    "    \"Date to\": pd.Timestamp(\"2023-01-01 00:00:00\"),\n",
    "}\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "Processed_Installed_Capacity_Germany_hourly = pd.concat(\n",
    "    [Processed_Installed_Capacity_Germany, new_row_df], ignore_index=True\n",
    ")\n",
    "\n",
    "Processed_Installed_Capacity_Germany_hourly = (\n",
    "    Processed_Installed_Capacity_Germany_hourly.set_index(\"Date from\")\n",
    ")\n",
    "Processed_Installed_Capacity_Germany_hourly = (\n",
    "    Processed_Installed_Capacity_Germany_hourly.resample(\"H\").mean()\n",
    ")\n",
    "Processed_Installed_Capacity_Germany_hourly.reset_index(inplace=True)\n",
    "Processed_Installed_Capacity_Germany_hourly[\"Date to\"] = (\n",
    "    Processed_Installed_Capacity_Germany_hourly[\"Date from\"] + pd.Timedelta(hours=1)\n",
    ")\n",
    "Processed_Installed_Capacity_Germany = Processed_Installed_Capacity_Germany_hourly\n",
    "Processed_Installed_Capacity_Germany = Processed_Installed_Capacity_Germany.fillna(\n",
    "    method=\"ffill\"\n",
    ")\n",
    "inspection.date_range_and_resolution(\n",
    "    Processed_Installed_Capacity_Germany, io.DATE_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trim rows of every df to have same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim first row of Processed_Weather_Data_Germany\n",
    "Processed_Weather_Data_Germany = Processed_Weather_Data_Germany[\n",
    "    Processed_Weather_Data_Germany[\"time\"]\n",
    "    != Processed_Weather_Data_Germany[\"time\"].min()\n",
    "]\n",
    "\n",
    "# trim last row of every other df\n",
    "Processed_Installed_Capacity_Germany = Processed_Installed_Capacity_Germany[\n",
    "    Processed_Installed_Capacity_Germany[\"Date to\"]\n",
    "    != Processed_Installed_Capacity_Germany[\"Date to\"].max()\n",
    "]\n",
    "Processed_Prices_Europe = Processed_Prices_Europe[\n",
    "    Processed_Prices_Europe[\"Date to\"] != Processed_Prices_Europe[\"Date to\"].max()\n",
    "]\n",
    "Processed_Realised_Supply_Germany = Processed_Realised_Supply_Germany[\n",
    "    Processed_Realised_Supply_Germany[\"Date to\"]\n",
    "    != Processed_Realised_Supply_Germany[\"Date to\"].max()\n",
    "]\n",
    "Processed_Realised_Demand_Germany = Processed_Realised_Demand_Germany[\n",
    "    Processed_Realised_Demand_Germany[\"Date to\"]\n",
    "    != Processed_Realised_Demand_Germany[\"Date to\"].max()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patch time saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Processed_Prices_Europe = preprocess.patch_time_saving(Processed_Prices_Europe)\n",
    "Processed_Realised_Demand_Germany = preprocess.patch_time_saving(\n",
    "    Processed_Realised_Demand_Germany\n",
    ")\n",
    "Processed_Realised_Supply_Germany = preprocess.patch_time_saving(\n",
    "    Processed_Realised_Supply_Germany\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.process_raw_data and CONF.data.normalize_data:\n",
    "    print(\"Split data in train, val and test\")\n",
    "    Processed_Installed_Capacity_Germany = preprocess.split_data(\n",
    "        df=Processed_Installed_Capacity_Germany, column_name=io.DATE_COLUMNS[-1]\n",
    "    )\n",
    "    Processed_Prices_Europe = preprocess.split_data(\n",
    "        df=Processed_Prices_Europe, column_name=io.DATE_COLUMNS[-1]\n",
    "    )\n",
    "    Processed_Realised_Supply_Germany = preprocess.split_data(\n",
    "        df=Processed_Realised_Supply_Germany, column_name=io.DATE_COLUMNS[-1]\n",
    "    )\n",
    "    Processed_Realised_Demand_Germany = preprocess.split_data(\n",
    "        df=Processed_Realised_Demand_Germany, column_name=io.DATE_COLUMNS[-1]\n",
    "    )\n",
    "    Processed_Weather_Data_Germany = preprocess.split_data(\n",
    "        df=Processed_Weather_Data_Germany, column_name=io.DATE_COLUMNS_WEATHER[0]\n",
    "    )\n",
    "\n",
    "    print(\"Normalizing data\")\n",
    "    (\n",
    "        Processed_Installed_Capacity_Germany,\n",
    "        Processed_Installed_Capacity_Germany_Scalers,\n",
    "    ) = preprocess.normalize_data(\n",
    "        df=Processed_Installed_Capacity_Germany,\n",
    "        ignore_features=io.DATE_COLUMNS,\n",
    "        constant=CONF.data.price_normalization_constant,\n",
    "    )\n",
    "\n",
    "    Processed_Prices_Europe, Processed_Prices_Europe_Scalers = (\n",
    "        preprocess.normalize_data(\n",
    "            df=Processed_Prices_Europe,\n",
    "            ignore_features=io.DATE_COLUMNS,\n",
    "            constant=CONF.data.price_normalization_constant,\n",
    "        )\n",
    "    )\n",
    "    Processed_Realised_Supply_Germany, Processed_Realised_Supply_Germany_Scalers = (\n",
    "        preprocess.normalize_data(\n",
    "            df=Processed_Realised_Supply_Germany, ignore_features=io.DATE_COLUMNS\n",
    "        )\n",
    "    )\n",
    "    Processed_Realised_Demand_Germany, Processed_Realised_Demand_Germany_Scalers = (\n",
    "        preprocess.normalize_data(\n",
    "            df=Processed_Realised_Demand_Germany, ignore_features=io.DATE_COLUMNS\n",
    "        )\n",
    "    )\n",
    "    Processed_Weather_Data_Germany, Processed_Weather_Data_Germany_Scalers = (\n",
    "        preprocess.normalize_data(\n",
    "            df=Processed_Weather_Data_Germany,\n",
    "            ignore_features=io.DATE_COLUMNS_WEATHER + [\"longitude\", \"latitude\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"Remove train, test, val columns, again\")\n",
    "    Processed_Installed_Capacity_Germany = Processed_Installed_Capacity_Germany.drop(\n",
    "        [\"train\", \"val\", \"test\"], axis=1\n",
    "    )\n",
    "    Processed_Prices_Europe = Processed_Prices_Europe.drop(\n",
    "        [\"train\", \"val\", \"test\"], axis=1\n",
    "    )\n",
    "    Processed_Realised_Supply_Germany = Processed_Realised_Supply_Germany.drop(\n",
    "        [\"train\", \"val\", \"test\"], axis=1\n",
    "    )\n",
    "    Processed_Realised_Demand_Germany = Processed_Realised_Demand_Germany.drop(\n",
    "        [\"train\", \"val\", \"test\"], axis=1\n",
    "    )\n",
    "    Processed_Weather_Data_Germany = Processed_Weather_Data_Germany.drop(\n",
    "        [\"train\", \"val\", \"test\"], axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate profile reports\n",
    "\n",
    "if CONF.data.inspect:\n",
    "    data.save_data_inspection(\n",
    "        Installed_Capacity_Germany=Processed_Installed_Capacity_Germany,\n",
    "        Prices_Europe=Processed_Prices_Europe,\n",
    "        Realised_Supply_Germany=Processed_Realised_Supply_Germany,\n",
    "        Realised_Demand_Germany=Processed_Realised_Demand_Germany,\n",
    "        Weather_Data_Germany=Processed_Weather_Data_Germany,\n",
    "        CONF=CONF,\n",
    "        data_type=\"preprocessed\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.plot:\n",
    "    plots.plot_df(\n",
    "        Processed_Installed_Capacity_Germany, \"Installed_Capacity_Germany\", CONF\n",
    "    )\n",
    "    plots.plot_df(Processed_Prices_Europe, \"Prices_Europe\", CONF)\n",
    "    plots.plot_df(Processed_Realised_Supply_Germany, \"Realised_Supply_Germany\", CONF)\n",
    "    plots.plot_df(Processed_Realised_Demand_Germany, \"Realised_Demand_Germany\", CONF)\n",
    "    plots.plot_df(\n",
    "        Processed_Weather_Data_Germany,\n",
    "        \"Weather_Data_Germany\",\n",
    "        CONF,\n",
    "        date_col=io.DATE_COLUMNS_WEATHER[-1],\n",
    "        drop_date_cols=io.DATE_COLUMNS_WEATHER,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect time's resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection.date_range_and_resolution_dfs(\n",
    "    Installed_Capacity_Germany=Processed_Installed_Capacity_Germany,\n",
    "    Prices_Europe=Processed_Prices_Europe,\n",
    "    Realised_Supply_Germany=Processed_Realised_Supply_Germany,\n",
    "    Realised_Demand_Germany=Processed_Realised_Demand_Germany,\n",
    "    Weather_Data_Germany=Processed_Weather_Data_Germany,\n",
    "    processed=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    Processed_Installed_Capacity_Germany,\n",
    "    Processed_Prices_Europe,\n",
    "    Processed_Realised_Supply_Germany,\n",
    "    Processed_Realised_Demand_Germany,\n",
    "]\n",
    "\n",
    "raw_dfs = [\n",
    "    Installed_Capacity_Germany_Raw,\n",
    "    Prices_Europe_Raw,\n",
    "    Realised_Supply_Germany_Raw,\n",
    "    Realised_Demand_Germany_Raw,\n",
    "]\n",
    "\n",
    "\n",
    "# assert all data frames have same length.\n",
    "def test_dataframe_lengths(dfs):\n",
    "    expected_length = len(dfs[0])\n",
    "    for df in dfs[1:]:\n",
    "        assert len(df) == expected_length, \"DataFrames have different lengths\"\n",
    "\n",
    "\n",
    "test_dataframe_lengths(dfs)\n",
    "\n",
    "\n",
    "# assert all data frames have have same time resolution\n",
    "def test_dataframe_resolutions(dfs):\n",
    "    date_column = \"Date from\"\n",
    "    expected_resolution = dfs[0][date_column].diff().dropna().mode()[0]\n",
    "    for df in dfs[1:]:\n",
    "        current_resolution = df[date_column].diff().dropna().mode()[0]\n",
    "        assert (\n",
    "            current_resolution == expected_resolution\n",
    "        ), \"DataFrames have different time resolutions\"\n",
    "    current_resolution = (\n",
    "        Processed_Weather_Data_Germany[\"time\"].diff().dropna().mode()[0]\n",
    "    )\n",
    "    assert (\n",
    "        current_resolution == expected_resolution\n",
    "    ), \"DataFrames have different time resolutions\"\n",
    "\n",
    "\n",
    "test_dataframe_resolutions(dfs)\n",
    "\n",
    "\n",
    "# Assert every row of every df has the same \"Date to\"\n",
    "def test_date_to_consistency(dfs):\n",
    "    date_to_values = dfs[0][\"Date to\"].values\n",
    "    for i, df in enumerate(dfs[1:]):\n",
    "        assert all(\n",
    "            df[\"Date to\"].values == date_to_values\n",
    "        ), f\"Mismatch in 'Date to' values across DataFrames {i + 1}\"\n",
    "    assert np.all(\n",
    "        Processed_Weather_Data_Germany[\"time\"].values == date_to_values\n",
    "    ), \"DataFrames have different time resolutions\"\n",
    "\n",
    "\n",
    "test_date_to_consistency(dfs)\n",
    "\n",
    "\n",
    "# assert that not cell is missed\n",
    "def test_no_missing_cells(dfs):\n",
    "    for i, df in enumerate(dfs + [Processed_Weather_Data_Germany]):\n",
    "        for column in df.columns:\n",
    "            assert (\n",
    "                df[column].isnull().sum() == 0\n",
    "            ), f\"Missing values found in column '{column}' of DataFrame at index {i}\"\n",
    "\n",
    "\n",
    "test_no_missing_cells(dfs)\n",
    "\n",
    "\n",
    "# assert that raw dfs and normal dfs have same set of columns\n",
    "def test_same_columns(raw_dfs, processed_dfs, ignore_columns=None):\n",
    "    if ignore_columns is None:\n",
    "        ignore_columns = set()\n",
    "\n",
    "    for raw_df, processed_df in zip(raw_dfs, processed_dfs):\n",
    "        raw_columns = set(raw_df.columns) - ignore_columns\n",
    "        processed_columns = set(processed_df.columns) - ignore_columns\n",
    "\n",
    "        assert (\n",
    "            raw_columns == processed_columns\n",
    "        ), f\"Column mismatch between raw and processed DataFrames. Missing {raw_columns - processed_columns} or {processed_columns - raw_columns}\"\n",
    "\n",
    "\n",
    "# Example usage of the function, ignoring 'train', 'val', and 'test'\n",
    "test_same_columns(\n",
    "    raw_dfs,\n",
    "    dfs,\n",
    "    ignore_columns={\n",
    "        \"∅ Neighbouring DE/LU [€/MWh]\",\n",
    "        \"Hungary [€/MWh]\",\n",
    "        \"Poland [€/MWh]\",\n",
    "        \"DE/AT/LU [€/MWh]\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader for supply forecasting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge data together to a single frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(df, prefix):\n",
    "    \"\"\"\n",
    "    Add a prefix to all column names except the merge key.\n",
    "    \"\"\"\n",
    "    return df.rename(\n",
    "        columns={\n",
    "            col: prefix + col if col not in io.DATE_COLUMNS else col\n",
    "            for col in df.columns\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "Suffix_Processed_Prices_Europe = add_prefix(Processed_Prices_Europe, \"prices_\")\n",
    "Suffix_Processed_Installed_Capacity_Germany = add_prefix(\n",
    "    Processed_Installed_Capacity_Germany, \"capacity_\"\n",
    ")\n",
    "Suffix_Processed_Realised_Supply_Germany = add_prefix(\n",
    "    Processed_Realised_Supply_Germany, \"supply_\"\n",
    ")\n",
    "Suffix_Processed_Realised_Demand_Germany = add_prefix(\n",
    "    Processed_Realised_Demand_Germany, \"demand_\"\n",
    ")\n",
    "Suffix_Processed_Weather_Data_Germany = add_prefix(\n",
    "    Processed_Weather_Data_Germany, \"weather_\"\n",
    ")\n",
    "Suffix_Processed_Weather_Data_Germany = Suffix_Processed_Weather_Data_Germany.rename(\n",
    "    columns={\"weather_time\": \"Date to\"}\n",
    ")\n",
    "\n",
    "# Now perform the merge\n",
    "df = pd.merge(\n",
    "    Suffix_Processed_Prices_Europe,\n",
    "    Suffix_Processed_Installed_Capacity_Germany,\n",
    "    on=io.DATE_COLUMNS,\n",
    "    how=\"inner\",\n",
    ")\n",
    "df = pd.merge(\n",
    "    df, Suffix_Processed_Realised_Supply_Germany, on=io.DATE_COLUMNS, how=\"inner\"\n",
    ")\n",
    "df = pd.merge(\n",
    "    df, Suffix_Processed_Realised_Demand_Germany, on=io.DATE_COLUMNS, how=\"inner\"\n",
    ")\n",
    "df = pd.merge(\n",
    "    df, Suffix_Processed_Weather_Data_Germany, on=io.DATE_COLUMNS[-1], how=\"inner\"\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF.data.plot:\n",
    "    plots.plot_df(df, \"Final Dataframe\", CONF, figsize=(150, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess.split_data(df=df, column_name=io.DATE_COLUMNS[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Torch's datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pipeline.config import CONF\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, CONF):\n",
    "        self.dataframe = df\n",
    "        self.features = CONF.model.features\n",
    "        self.targets = CONF.model.targets\n",
    "\n",
    "        # Set lag based on the horizon\n",
    "        if CONF.model.horizon == 1:\n",
    "            self.lag = CONF.model.supply1.lag\n",
    "        elif CONF.model.horizon == 24:\n",
    "            self.lag = CONF.model.supply24.lag\n",
    "        else:\n",
    "            raise ValueError(\"Horizon must be 1 or 24 hours\")\n",
    "\n",
    "        self.horizon = CONF.model.horizon\n",
    "        # Calculate total samples considering the number of lag and the forecasting horizon\n",
    "        self.total_samples = len(df) - (self.lag + self.horizon)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx += self.lag  # Adjust start index to accommodate initial lag\n",
    "        # Collect inputs using lag\n",
    "        inputs = []\n",
    "        for lag in range(self.lag):\n",
    "            lag_idx = idx - lag\n",
    "            inputs.append(\n",
    "                self.dataframe.loc[lag_idx, self.features].values.astype(float)\n",
    "            )  # n_features\n",
    "        inputs = torch.tensor(inputs)  # Shape: [lag, n_features]\n",
    "\n",
    "        # Collect targets based on the horizon\n",
    "        targets_idx = idx + self.horizon\n",
    "        targets = torch.tensor(\n",
    "            self.dataframe.loc[targets_idx, self.targets].values.astype(float)\n",
    "        )\n",
    "\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torch's dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"train\"]].drop(CONF.model.ignore_columns, axis=1)\n",
    "val_df = df[df[\"val\"]].drop(CONF.model.ignore_columns, axis=1)\n",
    "test_df = df[df[\"test\"]].drop(CONF.model.ignore_columns, axis=1)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_df, CONF=CONF)\n",
    "val_dataset = TimeSeriesDataset(val_df, CONF=CONF)\n",
    "test_dataset = TimeSeriesDataset(test_df, CONF=CONF)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONF.model.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONF.model.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONF.model.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-energy-system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
